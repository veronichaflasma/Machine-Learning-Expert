# -*- coding: utf-8 -*-
"""Credit Scoring Classifications.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xmDCcsZzwazfYQ-hSk41YNT_SJUwH0Zf

# **Credit Scoring Classification**

**Name: Flasma Veronicha H**

# **1. Import Library**
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

# Model Library
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.ensemble import AdaBoostRegressor

from sklearn.preprocessing import StandardScaler

"""# **2. Data Collection**

Import datasets from Kaggle
"""

# Install Kaggle package
!pip install -q Kaggle

# Upload Kaggle API
from google.colab import files
files.upload()

# Create directory and change the permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# Download and copy the dataset's API
!kaggle datasets download -d sudhanshu2198/processed-data-credit-score

# Unzip the dataset
!mkdir credit-scoring
!unzip processed-data-credit-score.zip -d credit-scoring
!ls credit-scoring

"""# **3. Data Understanding**"""

credit = pd.read_csv("/content/credit-scoring/Score.csv")
credit.head()

"""**credit.info()** is use for quickly understanding the structure and composition of the DataFrame. It helps to identify missing values, understand the data types, and estimate the memory footprint of the DataFrame."""

credit.info()

"""**credit.describe()** to understanding the distribution and basic statistics of numerical data within the DataFrame. It provides insights into the central tendency, spread, and range of values for each numerical column"""

credit.describe().T

"""# **4. Exploratory Data Analysis (EDA)**

This step is to analyzing data sets to summarize main characteristics, often with visual methods.

* **Delay_from_due_date:** Represents the average number of days delayed from the payment date
* **Num_of_Delayed_Payment:** Represents the average number of payments delayed by a person
* **Num_Credit_Inquiries:** Represents the number of credit card inquiries
* **Credit_Utilization_Ratio:** Represents the utilization ratio of credit card
* **Credit_History_Age:** Represents the age of credit history of the person
* **Amount_invested_monthly:** Represents the monthly amount invested by the customer (in USD)
* **Monthly_Balance:** Represents the monthly balance amount of the customer (in USD)
* **Age:** Represents the age of the person
* **Annual_Income:** Represents the annual income of the person
* **Num_Bank_Accounts:** Represents the number of bank accounts a person holds
* **Num_Credit_Card:** Represents the number of other credit cards held by a person
* **Interest_Rate:** Represents the interest rate on credit card
* **Num_of_Loan:** Represents the number of loans taken from the bank
* **Monthly_Inhand_Salary:** Represents the monthly base salary of a person
* **Outstanding_Debt:** Represents the remaining debt to be paid (in USD)
* **Total_EMI_per_month:** Represents the monthly EMI payments (in USD)
"""

# Function to visualize the target variable distribution
def visualize_class(data, target_encoding='Credit_Score', figsize=(10, 4), palette='viridis'):
    sns.set_style('whitegrid')
    plt.figure(figsize=figsize)

    rel_freq = data[target_encoding].value_counts(normalize=True, ascending=False) * 100

    ax = sns.barplot(x=rel_freq.values, y=rel_freq.index, palette=palette)

    for i in range(rel_freq.shape[0]):
        ax.text(rel_freq.values[i] + 0.5, i, str(round(rel_freq.values[i], 1)) + '%',
                ha='left', va='center', color='black', fontsize=10)

    # Calculate total count of data points
    total_count = len(data)

    # Calculate value counts of each class/category
    class_counts = data[target_encoding].value_counts()

    class_info = ', '.join([f'{class_name}: {class_count}' for class_name, class_count in class_counts.items()])
    plt.text(0, -1, f'Total Data: {total_count}\n{class_info}', ha='left', va='center', fontsize=12)

    plt.xlabel('Relative Frequency (%)', fontsize=14)
    plt.ylabel(target_encoding.replace('_', ' ').title(), fontsize=14)
    plt.tight_layout()
    plt.show()

visualize_class(credit)
plt.savefig("image1.png")

"""In the context of credit analysis, the classification of **Credit Scores** into 3 categories - Good, Poor, and Standard - serves as a fundamental tool for evaluating the creditworthiness of individuals or entities. This classification process involves assessing various financial indicators and behavioral patterns associated with borrowers to determine their level of credit risk.

## **4.1 EDA - Univariate Analysis**
"""

credit.hist(bins=50, figsize=(20,15))
plt.savefig(f"Univariate Analysis.png")
plt.show()

"""## **4.3 EDA - Analyze Correlation Credit Score**"""

col = ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',
       'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan',
       'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit',
       'Num_Credit_Inquiries', 'Outstanding_Debt',
       'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month',
       'Amount_invested_monthly', 'Monthly_Balance']

for c in col:
    fig = px.histogram(credit, x='Credit_Score', y=c,
                       histfunc='avg',
                       title=f"Relation between Credit_Score and {c}",
                       width=600, height=400)
    fig.show()
    plt.savefig(f"Analyze Correlation Credit Score.png")

plt.figure(figsize=(10, 8))
correlation_matrix = credit.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title(f"Correlation Matrix for Numeric Features", size=20)
plt.savefig(f"Correlation Matrix.png")

"""# **5. Data Preparation**"""

# Checking Missing Values in Each Column
missing = credit.isnull().sum()
missing_val = pd.DataFrame({'Missing Values': missing})
print(missing_val)

# Checking Duplicate Values
duplicate = credit.duplicated().sum()
print('Total of Duplicate Values: ', duplicate)

"""This step is replacing the value "NM" in the column 'Payment_of_Min_Amount' with the second most frequent value found in that column."""

credit['Payment_of_Min_Amount'].value_counts()

freq = credit['Payment_of_Min_Amount'].value_counts()
credit['Payment_of_Min_Amount'].replace({"NM":freq.index[1]},inplace=True)

credit['Credit_Mix'].value_counts()

credit['Credit_Score'] = credit['Credit_Score'].map({"Standard": 0, "Poor": 1, "Good": 2})
credit['Payment_of_Min_Amount'] = credit['Payment_of_Min_Amount'].map({"Yes": 0, "No": 1})
credit['Credit_Mix'] = credit['Credit_Mix'].map({"Standard": 0, "Good": 1, "Bad": 2})
credit['Payment_Behaviour'] = credit['Payment_Behaviour'].map(
    {"Low_spent_Small_value_payments": 0,
     "High_spent_Medium_value_payments": 1,
     "High_spent_Large_value_payments": 2,
     "Low_spent_Medium_value_payments": 3,
     "High_spent_Small_value_payments": 4,
     "Low_spent_Large_value_payments": 5,
     })

credit.head()

X = credit.drop('Credit_Score', axis=1)
y = credit['Credit_Score']

"""Splitting datasets 20% test size"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=14)

# fit transform X_train, but not X_test
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Make sure there is no missing value
missing = credit['Credit_Mix'].isnull().sum()
print(missing)

"""# **6. Build Model Classifier**"""

model_predict = []

"""## **6.1 KNN Classifier**"""

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

model_predict.append(y_pred)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred, zero_division=0)
conf_matrix = confusion_matrix(y_test, y_pred)

# Print Accuracy and Classification Report
print(f"Accuracy: {accuracy}")
print(f"Classification Report: \n{classification_rep}")

# Visualize the confusion matrix
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix, annot=True, fmt='g', cbar=False,
            xticklabels=['Good', 'Standard', 'Poor'],
            yticklabels=['Good', 'Standard', 'Poor'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

plt.tight_layout()
plt.show()
plt.savefig(f"KNN.png")

"""## **6.2 Random Forest Classifier**"""

rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

model_predict.append(y_pred)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred, zero_division=0)
conf_matrix = confusion_matrix(y_test, y_pred)

# Print Accuracy and Classification Report
print(f"Accuracy: {accuracy}")
print(f"Classification Report: \n{classification_rep}")

# Visualize the confusion matrix
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix, annot=True, fmt='g', cbar=False,
            xticklabels=['Good', 'Standard', 'Poor'],
            yticklabels=['Good', 'Standard', 'Poor'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

plt.tight_layout()
plt.show()
plt.savefig(f"KNN.png")

"""## **6.3 Naive Bayes Classifier**"""

nb = BernoulliNB()
nb.fit(X_train, y_train)
y_pred = nb.predict(X_test)

model_predict.append(y_pred)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred, zero_division=0)
conf_matrix = confusion_matrix(y_test, y_pred)

# Print Accuracy and Classification Report
print(f"Accuracy: {accuracy}")
print(f"Classification Report: \n{classification_rep}")

# Visualize the confusion matrix
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix, annot=True, fmt='g', cbar=False,
            xticklabels=['Good', 'Standard', 'Poor'],
            yticklabels=['Good', 'Standard', 'Poor'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

plt.tight_layout()
plt.show()
plt.savefig(f"nb.png")

"""# **7. Evaluation**"""

models = ['KNN', 'Random Forest', 'Naive Bayes']

accuracy = [accuracy_score(y_test, y_pred) for y_pred in model_predict]
precision = [precision_score(y_test, y_pred, average='weighted', zero_division=0) for y_pred in model_predict]
recall = [recall_score(y_test, y_pred, average='weighted', zero_division=0) for y_pred in model_predict]
f1 = [f1_score(y_test, y_pred, average='weighted') for y_pred in model_predict]

fig, axs = plt.subplots(2, 2, figsize=(12, 8))

metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}
colors = ['royalblue', 'orange', 'darkorchid']

for i, (metric_name, metric_values) in enumerate(metrics.items()):
    ax = axs[i // 2, i % 2]
    bars = ax.bar(models, metric_values, color=colors)
    ax.set_title(metric_name)
    ax.set_ylabel(metric_name)
    ax.set_ylim(0.6, 0.9)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), va='bottom', ha='center', fontsize=10, color='black')

# Add title to the entire figure
fig.suptitle('Model Comparison & Evaluation', fontsize=16)
plt.tight_layout()
plt.show()
plt.savefig("Result.png")